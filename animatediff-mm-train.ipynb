{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1436057,"sourceType":"datasetVersion","datasetId":841381}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/guoyww/AnimateDiff.git\n%cd AnimateDiff\n!pip install -r requirements.txt\n\n\n!pip install \"jax[cuda12_local]==0.4.23\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:42:18.306925Z","iopub.execute_input":"2024-08-16T12:42:18.307295Z","iopub.status.idle":"2024-08-16T12:45:50.538084Z","shell.execute_reply.started":"2024-08-16T12:42:18.307264Z","shell.execute_reply":"2024-08-16T12:45:50.537040Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'AnimateDiff'...\nremote: Enumerating objects: 718, done.\u001b[K\nremote: Counting objects: 100% (71/71), done.\u001b[K\nremote: Compressing objects: 100% (53/53), done.\u001b[K\nremote: Total 718 (delta 21), reused 54 (delta 16), pack-reused 647 (from 1)\u001b[K\nReceiving objects: 100% (718/718), 60.38 MiB | 18.35 MiB/s, done.\nResolving deltas: 100% (273/273), done.\n/kaggle/working/AnimateDiff\nCollecting torch==2.3.1 (from -r requirements.txt (line 1))\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting torchvision==0.18.1 (from -r requirements.txt (line 2))\n  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nCollecting diffusers==0.11.1 (from -r requirements.txt (line 3))\n  Downloading diffusers-0.11.1-py3-none-any.whl.metadata (29 kB)\nCollecting transformers==4.25.1 (from -r requirements.txt (line 4))\n  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xformers==0.0.27 (from -r requirements.txt (line 5))\n  Downloading xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting imageio==2.27.0 (from -r requirements.txt (line 6))\n  Downloading imageio-2.27.0-py3-none-any.whl.metadata (4.8 kB)\nCollecting imageio-ffmpeg==0.4.9 (from -r requirements.txt (line 7))\n  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\nCollecting decord==0.6.0 (from -r requirements.txt (line 8))\n  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\nCollecting omegaconf==2.3.0 (from -r requirements.txt (line 9))\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting gradio==3.36.1 (from -r requirements.txt (line 10))\n  Downloading gradio-3.36.1-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.4.3)\nCollecting einops (from -r requirements.txt (line 12))\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.17.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 1)) (2024.5.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.1 (from torch==2.3.1->-r requirements.txt (line 1))\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.18.1->-r requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.18.1->-r requirements.txt (line 2)) (9.5.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers==0.11.1->-r requirements.txt (line 3)) (6.11.0)\nRequirement already satisfied: huggingface-hub>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.11.1->-r requirements.txt (line 3)) (0.23.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.11.1->-r requirements.txt (line 3)) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers==0.11.1->-r requirements.txt (line 3)) (2.32.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->-r requirements.txt (line 4)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->-r requirements.txt (line 4)) (6.0.1)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1->-r requirements.txt (line 4))\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->-r requirements.txt (line 4)) (4.66.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio-ffmpeg==0.4.9->-r requirements.txt (line 7)) (69.0.3)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0->-r requirements.txt (line 9))\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (22.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (3.9.1)\nRequirement already satisfied: altair>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (5.3.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (0.108.0)\nCollecting ffmpy (from gradio==3.36.1->-r requirements.txt (line 10))\n  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting gradio-client>=0.2.7 (from gradio==3.36.1->-r requirements.txt (line 10))\n  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (0.27.0)\nRequirement already satisfied: markdown-it-py>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.36.1->-r requirements.txt (line 10)) (3.0.0)\nRequirement already satisfied: markupsafe in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (2.1.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (3.7.5)\nCollecting mdit-py-plugins<=0.3.3 (from gradio==3.36.1->-r requirements.txt (line 10))\n  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: orjson in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (3.9.10)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (2.2.2)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (2.5.3)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (0.25.1)\nRequirement already satisfied: pygments>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (2.17.2)\nCollecting python-multipart (from gradio==3.36.1->-r requirements.txt (line 10))\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nCollecting semantic-version (from gradio==3.36.1->-r requirements.txt (line 10))\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (0.25.0)\nRequirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.36.1->-r requirements.txt (line 10)) (12.0)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->-r requirements.txt (line 1))\n  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 13)) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 13)) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 13)) (3.1.41)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 13)) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 13)) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 13)) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 13)) (2.8.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 13)) (1.3.3)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.36.1->-r requirements.txt (line 10)) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.36.1->-r requirements.txt (line 10)) (0.12.1)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 13)) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 13)) (4.0.11)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.36.1->-r requirements.txt (line 10)) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.36.1->-r requirements.txt (line 10)) (2024.7.4)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.36.1->-r requirements.txt (line 10)) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.36.1->-r requirements.txt (line 10)) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.36.1->-r requirements.txt (line 10)) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->gradio==3.36.1->-r requirements.txt (line 10)) (0.14.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.36.1->-r requirements.txt (line 10)) (0.1.2)\nRequirement already satisfied: linkify-it-py<3,>=1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.36.1->-r requirements.txt (line 10)) (2.0.3)\nINFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\nCollecting mdit-py-plugins<=0.3.3 (from gradio==3.36.1->-r requirements.txt (line 10))\n  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl.metadata (2.6 kB)\nINFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl.metadata (2.6 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl.metadata (2.6 kB)\nCollecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.36.1->-r requirements.txt (line 10))\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n  Downloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.25.1->-r requirements.txt (line 4)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio==3.36.1->-r requirements.txt (line 10)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio==3.36.1->-r requirements.txt (line 10)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio==3.36.1->-r requirements.txt (line 10)) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.11.1->-r requirements.txt (line 3)) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.11.1->-r requirements.txt (line 3)) (1.26.18)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.36.1->-r requirements.txt (line 10)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.36.1->-r requirements.txt (line 10)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.36.1->-r requirements.txt (line 10)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.36.1->-r requirements.txt (line 10)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.36.1->-r requirements.txt (line 10)) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.36.1->-r requirements.txt (line 10)) (4.0.3)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio==3.36.1->-r requirements.txt (line 10)) (0.32.0.post1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->gradio==3.36.1->-r requirements.txt (line 10)) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic->gradio==3.36.1->-r requirements.txt (line 10)) (2.14.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers==0.11.1->-r requirements.txt (line 3)) (3.17.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.36.1->-r requirements.txt (line 10)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.36.1->-r requirements.txt (line 10)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.36.1->-r requirements.txt (line 10)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.36.1->-r requirements.txt (line 10)) (1.4.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.1->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 13)) (5.0.1)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.36.1->-r requirements.txt (line 10)) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.36.1->-r requirements.txt (line 10)) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.36.1->-r requirements.txt (line 10)) (0.16.2)\nRequirement already satisfied: uc-micro-py in /opt/conda/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.36.1->-r requirements.txt (line 10)) (1.0.3)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->gradio==3.36.1->-r requirements.txt (line 10)) (1.2.0)\nDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading diffusers-0.11.1-py3-none-any.whl (524 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.9/524.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (164.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading imageio-2.27.0-py3-none-any.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gradio-3.36.1-py3-none-any.whl (19.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\nDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=f6ef15d6c11661a25b8acaee2b9fa09c41b77bab34509122f745df6f91ce278d\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\nSuccessfully built antlr4-python3-runtime\nInstalling collected packages: tokenizers, antlr4-python3-runtime, triton, semantic-version, python-multipart, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markdown-it-py, imageio-ffmpeg, imageio, ffmpy, einops, decord, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mdit-py-plugins, transformers, nvidia-cusolver-cu12, gradio-client, diffusers, torch, xformers, torchvision, gradio\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: markdown-it-py\n    Found existing installation: markdown-it-py 3.0.0\n    Uninstalling markdown-it-py-3.0.0:\n      Successfully uninstalled markdown-it-py-3.0.0\n  Attempting uninstall: imageio\n    Found existing installation: imageio 2.33.1\n    Uninstalling imageio-2.33.1:\n      Successfully uninstalled imageio-2.33.1\n  Attempting uninstall: mdit-py-plugins\n    Found existing installation: mdit-py-plugins 0.4.0\n    Uninstalling mdit-py-plugins-0.4.0:\n      Successfully uninstalled mdit-py-plugins-0.4.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.42.3\n    Uninstalling transformers-4.42.3:\n      Successfully uninstalled transformers-4.42.3\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.16.2\n    Uninstalling torchvision-0.16.2:\n      Successfully uninstalled torchvision-0.16.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.15 requires transformers>=4.33.1, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 decord-0.6.0 diffusers-0.11.1 einops-0.8.0 ffmpy-0.4.0 gradio-3.36.1 gradio-client-1.3.0 imageio-2.27.0 imageio-ffmpeg-0.4.9 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 python-multipart-0.0.9 semantic-version-2.10.0 tokenizers-0.13.3 torch-2.3.1 torchvision-0.18.1 transformers-4.25.1 triton-2.3.1 xformers-0.0.27\nLooking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\nCollecting jax==0.4.23 (from jax[cuda12_local]==0.4.23)\n  Downloading jax-0.4.23-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.23->jax[cuda12_local]==0.4.23) (0.2.0)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.23->jax[cuda12_local]==0.4.23) (1.26.4)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax==0.4.23->jax[cuda12_local]==0.4.23) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.23->jax[cuda12_local]==0.4.23) (1.11.4)\n\u001b[33mWARNING: jax 0.4.23 does not provide the extra 'cuda12-local'\u001b[0m\u001b[33m\n\u001b[0mCollecting jaxlib==0.4.23+cuda12.cudnn89 (from jax[cuda12_local]==0.4.23)\n  Downloading https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.23%2Bcuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl (131.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jax-0.4.23-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: jaxlib, jax\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.4.26.dev20240504\n    Uninstalling jaxlib-0.4.26.dev20240504:\n      Successfully uninstalled jaxlib-0.4.26.dev20240504\n  Attempting uninstall: jax\n    Found existing installation: jax 0.4.26\n    Uninstalling jax-0.4.26:\n      Successfully uninstalled jax-0.4.26\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\norbax-checkpoint 0.5.20 requires jax>=0.4.26, but you have jax 0.4.23 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed jax-0.4.23 jaxlib-0.4.23+cuda12.cudnn89\n","output_type":"stream"}]},{"cell_type":"code","source":"# İlk olarak ruamel.yaml kütüphanesini yükleyelim\n!pip install ruamel.yaml\n\n# Gerekli kütüphaneleri içe aktaralım\nfrom ruamel.yaml import YAML\n\n# YAML dosyasını okuma ve düzenleme fonksiyonu\ndef update_yaml_config(file_path):\n    yaml = YAML()\n\n    # Mevcut YAML dosyasını oku\n    with open(file_path, 'r') as file:\n        config = yaml.load(file)\n\n    # Değişiklik yapmak istediğiniz bölümleri buraya ekleyin\n    config['image_finetune'] = False\n    config['output_dir'] = \"/kaggle/working/\"\n    config['pretrained_model_path'] = \"black-forest-labs/FLUX.1-dev\"\n    \n    config['unet_additional_kwargs'] = {\n        'use_motion_module': True,\n        'motion_module_resolutions': [1, 2, 4, 8],\n        'unet_use_cross_frame_attention': False,\n        'unet_use_temporal_attention': False,\n        'motion_module_type': \"Vanilla\",\n        'motion_module_kwargs': {\n            'num_attention_heads': 8,\n            'num_transformer_block': 1,\n            'attention_block_types': [\"Temporal_Self\", \"Temporal_Self\"],\n            'temporal_position_encoding': True,\n            'temporal_position_encoding_max_len': 24,\n            'temporal_attention_dim_div': 1,\n            'zero_initialize': True\n        }\n    }\n\n    config['noise_scheduler_kwargs'] = {\n        'num_train_timesteps': 1000,\n        'beta_start': 0.00085,\n        'beta_end': 0.012,\n        'beta_schedule': \"linear\",\n        'steps_offset': 1,\n        'clip_sample': False\n    }\n\n    config['train_data'] = {\n        'csv_path': \"/kaggle/working/video_data.csv\",\n        'video_folder': \"/kaggle/input/ucf101/UCF101/UCF-101/ApplyEyeMakeup\",\n        'sample_size': 256,\n        'sample_stride': 4,\n        'sample_n_frames': 16\n    }\n\n    config['validation_data'] = {\n        'prompts': [\n            \"Snow rocky mountains peaks canyon. Snow blanketed rocky mountains surround and shadow deep canyons.\",\n            \"A drone view of celebration with Christma tree and fireworks, starry sky - background.\",\n            \"Robot dancing in times square.\",\n            \"Pacific coast, carmel by the sea ocean and waves.\"\n        ],\n        'num_inference_steps': 25,\n        'guidance_scale': 8.0\n    }\n\n    config['trainable_modules'] = [\"motion_modules.\"]\n    config['unet_checkpoint_path'] = \"\"\n    config['learning_rate'] = 1e-4\n    config['train_batch_size'] = 4\n\n    config['max_train_epoch'] = -1\n    config['max_train_steps'] = 1\n    config['checkpointing_epochs'] = -1\n    config['checkpointing_steps'] = 60\n\n    config['validation_steps'] = 2500\n    config['validation_steps_tuple'] = [2, 50]\n\n    config['global_seed'] = 42\n    config['mixed_precision_training'] = True\n    config['enable_xformers_memory_efficient_attention'] = True\n    config['is_debug'] = False\n\n    # Güncellenmiş dosyayı geri yaz\n    with open(file_path, 'w') as file:\n        yaml.dump(config, file)\n\n# Fonksiyonu çağırarak YAML dosyasını güncelleyelim\nupdate_yaml_config('configs/training/v1/training.yaml')","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:48:03.230531Z","iopub.execute_input":"2024-08-16T12:48:03.231463Z","iopub.status.idle":"2024-08-16T12:48:15.717640Z","shell.execute_reply.started":"2024-08-16T12:48:03.231427Z","shell.execute_reply":"2024-08-16T12:48:15.716559Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ruamel.yaml in /opt/conda/lib/python3.10/site-packages (0.18.5)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml) (0.2.7)\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\n\ncsv_file_path = '/kaggle/working/video_data.csv'\nvideo_data = [\n    {'video_id': 1, 'video_path': '/kaggle/input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi', 'label': 'EyeMakeup'},\n    {'video_id': 2, 'video_path': '/kaggle/input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi', 'label': 'EyeMakeup'},\n    {'video_id': 3, 'video_path': '/kaggle/input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi', 'label': 'EyeMakeup'},\n    {'video_id': 4, 'video_path': '/kaggle/input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi', 'label': 'EyeMakeup'},\n    {'video_id': 5, 'video_path': '/kaggle/input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi', 'label': 'EyeMakeup'},\n]\n\nwith open(csv_file_path, mode='w', newline='') as file:\n    writer = csv.DictWriter(file, fieldnames=['video_id', 'video_path', 'label'])\n    writer.writeheader()\n    for video in video_data:\n        writer.writerow(video)\n\nprint(f\"CSV dosyası '{csv_file_path}' başarıyla oluşturuldu.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:46:02.996937Z","iopub.execute_input":"2024-08-16T12:46:02.997305Z","iopub.status.idle":"2024-08-16T12:46:03.005623Z","shell.execute_reply.started":"2024-08-16T12:46:02.997271Z","shell.execute_reply":"2024-08-16T12:46:03.004800Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"CSV dosyası '/kaggle/working/video_data.csv' başarıyla oluşturuldu.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nprint(\"CUDA Available:\", torch.cuda.is_available())\nprint(\"Current Device:\", torch.cuda.current_device())","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:46:03.007537Z","iopub.execute_input":"2024-08-16T12:46:03.007826Z","iopub.status.idle":"2024-08-16T12:46:04.847898Z","shell.execute_reply.started":"2024-08-16T12:46:03.007802Z","shell.execute_reply":"2024-08-16T12:46:04.846931Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"CUDA Available: True\nCurrent Device: 0\n","output_type":"stream"}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"Write_HF\")\nfrom huggingface_hub import login\n\nlogin(token=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:51:50.201843Z","iopub.execute_input":"2024-08-16T12:51:50.202517Z","iopub.status.idle":"2024-08-16T12:51:50.776174Z","shell.execute_reply.started":"2024-08-16T12:51:50.202482Z","shell.execute_reply":"2024-08-16T12:51:50.775201Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport math\nimport wandb\nimport random\nimport logging\nimport inspect\nimport argparse\nimport datetime\nimport subprocess\n\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom einops import rearrange\nfrom omegaconf import OmegaConf\nfrom safetensors import safe_open\nfrom typing import Dict, Optional, Tuple\n\nimport torch\nimport torchvision\nimport torch.nn.functional as F\nimport torch.distributed as dist\nfrom torch.optim.swa_utils import AveragedModel\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\nimport diffusers\nfrom diffusers import AutoencoderKL, DDIMScheduler\nfrom diffusers.models import UNet2DConditionModel\nfrom diffusers.pipelines import StableDiffusionPipeline\nfrom diffusers.optimization import get_scheduler\nfrom diffusers.utils import check_min_version\nfrom diffusers.utils.import_utils import is_xformers_available\n\nimport transformers\nfrom transformers import CLIPTextModel, CLIPTokenizer\n\nfrom animatediff.data.dataset import WebVid10M\nfrom animatediff.models.unet import UNet3DConditionModel\nfrom animatediff.pipelines.pipeline_animation import AnimationPipeline\nfrom animatediff.utils.util import save_videos_grid, zero_rank_print\n\n\n\ndef init_dist(launcher=\"slurm\", backend='nccl', port=29500, **kwargs):\n    \"\"\"Initializes distributed environment.\"\"\"\n    if launcher == 'pytorch':\n        rank = int(os.environ['RANK'])\n        num_gpus = torch.cuda.device_count()\n        local_rank = rank % num_gpus\n        torch.cuda.set_device(local_rank)\n        dist.init_process_group(backend=backend, **kwargs)\n        \n    elif launcher == 'slurm':\n        proc_id = int(os.environ['SLURM_PROCID'])\n        ntasks = int(os.environ['SLURM_NTASKS'])\n        node_list = os.environ['SLURM_NODELIST']\n        num_gpus = torch.cuda.device_count()\n        local_rank = proc_id % num_gpus\n        torch.cuda.set_device(local_rank)\n        addr = subprocess.getoutput(\n            f'scontrol show hostname {node_list} | head -n1')\n        os.environ['MASTER_ADDR'] = addr\n        os.environ['WORLD_SIZE'] = str(ntasks)\n        os.environ['RANK'] = str(proc_id)\n        port = os.environ.get('PORT', port)\n        os.environ['MASTER_PORT'] = str(port)\n        dist.init_process_group(backend=backend)\n        zero_rank_print(f\"proc_id: {proc_id}; local_rank: {local_rank}; ntasks: {ntasks}; node_list: {node_list}; num_gpus: {num_gpus}; addr: {addr}; port: {port}\")\n        \n    else:\n        raise NotImplementedError(f'Not implemented launcher type: `{launcher}`!')\n    \n    return local_rank\n\n\n\ndef main(\n    image_finetune: bool,\n    \n    name: str,\n    use_wandb: bool,\n    launcher: str,\n    \n    output_dir: str,\n    pretrained_model_path: str,\n\n    train_data: Dict,\n    validation_data: Dict,\n    cfg_random_null_text: bool = True,\n    cfg_random_null_text_ratio: float = 0.1,\n    \n    unet_checkpoint_path: str = \"\",\n    unet_additional_kwargs: Dict = {},\n    ema_decay: float = 0.9999,\n    noise_scheduler_kwargs = None,\n    \n    max_train_epoch: int = -1,\n    max_train_steps: int = 100,\n    validation_steps: int = 100,\n    validation_steps_tuple: Tuple = (-1,),\n\n    learning_rate: float = 3e-5,\n    scale_lr: bool = False,\n    lr_warmup_steps: int = 0,\n    lr_scheduler: str = \"constant\",\n\n    trainable_modules: Tuple[str] = (None, ),\n    num_workers: int = 32,\n    train_batch_size: int = 1,\n    adam_beta1: float = 0.9,\n    adam_beta2: float = 0.999,\n    adam_weight_decay: float = 1e-2,\n    adam_epsilon: float = 1e-08,\n    max_grad_norm: float = 1.0,\n    gradient_accumulation_steps: int = 1,\n    gradient_checkpointing: bool = False,\n    checkpointing_epochs: int = 5,\n    checkpointing_steps: int = -1,\n\n    mixed_precision_training: bool = True,\n    enable_xformers_memory_efficient_attention: bool = True,\n\n    global_seed: int = 42,\n    is_debug: bool = False,\n):\n    check_min_version(\"0.10.0.dev0\")\n\n    # Initialize distributed training\n    local_rank      = init_dist(launcher=launcher)\n    global_rank     = dist.get_rank()\n    num_processes   = dist.get_world_size()\n    is_main_process = global_rank == 0\n\n    seed = global_seed + global_rank\n    torch.manual_seed(seed)\n    \n    # Logging folder\n    folder_name = \"debug\" if is_debug else name + datetime.datetime.now().strftime(\"-%Y-%m-%dT%H-%M-%S\")\n    output_dir = os.path.join(output_dir, folder_name)\n    if is_debug and os.path.exists(output_dir):\n        os.system(f\"rm -rf {output_dir}\")\n\n    *_, config = inspect.getargvalues(inspect.currentframe())\n\n    # Make one log on every process with the configuration for debugging.\n    logging.basicConfig(\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        datefmt=\"%m/%d/%Y %H:%M:%S\",\n        level=logging.INFO,\n    )\n\n    if is_main_process and (not is_debug) and use_wandb:\n        run = wandb.init(project=\"animatediff\", name=folder_name, config=config)\n\n    # Handle the output folder creation\n    if is_main_process:\n        os.makedirs(output_dir, exist_ok=True)\n        os.makedirs(f\"{output_dir}/samples\", exist_ok=True)\n        os.makedirs(f\"{output_dir}/sanity_check\", exist_ok=True)\n        os.makedirs(f\"{output_dir}/checkpoints\", exist_ok=True)\n        OmegaConf.save(config, os.path.join(output_dir, 'config.yaml'))\n\n    # Load scheduler, tokenizer and models.\n    noise_scheduler = DDIMScheduler(**OmegaConf.to_container(noise_scheduler_kwargs))\n\n    vae          = AutoencoderKL.from_pretrained(pretrained_model_path, subfolder=\"vae\")\n    tokenizer    = CLIPTokenizer.from_pretrained(pretrained_model_path, subfolder=\"tokenizer\")\n    text_encoder = CLIPTextModel.from_pretrained(pretrained_model_path, subfolder=\"text_encoder\")\n    if not image_finetune:\n        unet = UNet3DConditionModel.from_pretrained_2d(\n            pretrained_model_path, subfolder=\"unet\", \n            unet_additional_kwargs=OmegaConf.to_container(unet_additional_kwargs)\n        )\n    else:\n        unet = UNet2DConditionModel.from_pretrained(pretrained_model_path, subfolder=\"unet\")\n        \n    # Load pretrained unet weights\n    if unet_checkpoint_path != \"\":\n        zero_rank_print(f\"from checkpoint: {unet_checkpoint_path}\")\n        unet_checkpoint_path = torch.load(unet_checkpoint_path, map_location=\"cpu\")\n        if \"global_step\" in unet_checkpoint_path: zero_rank_print(f\"global_step: {unet_checkpoint_path['global_step']}\")\n        state_dict = unet_checkpoint_path[\"state_dict\"] if \"state_dict\" in unet_checkpoint_path else unet_checkpoint_path\n\n        m, u = unet.load_state_dict(state_dict, strict=False)\n        zero_rank_print(f\"missing keys: {len(m)}, unexpected keys: {len(u)}\")\n        assert len(u) == 0\n        \n    # Freeze vae and text_encoder\n    vae.requires_grad_(False)\n    text_encoder.requires_grad_(False)\n    \n    # Set unet trainable parameters\n    unet.requires_grad_(False)\n    for name, param in unet.named_parameters():\n        for trainable_module_name in trainable_modules:\n            if trainable_module_name in name:\n                param.requires_grad = True\n                break\n            \n    trainable_params = list(filter(lambda p: p.requires_grad, unet.parameters()))\n    optimizer = torch.optim.AdamW(\n        trainable_params,\n        lr=learning_rate,\n        betas=(adam_beta1, adam_beta2),\n        weight_decay=adam_weight_decay,\n        eps=adam_epsilon,\n    )\n\n    if is_main_process:\n        zero_rank_print(f\"trainable params number: {len(trainable_params)}\")\n        zero_rank_print(f\"trainable params scale: {sum(p.numel() for p in trainable_params) / 1e6:.3f} M\")\n\n    # Enable xformers\n    if enable_xformers_memory_efficient_attention:\n        if is_xformers_available():\n            unet.enable_xformers_memory_efficient_attention()\n        else:\n            raise ValueError(\"xformers is not available. Make sure it is installed correctly\")\n\n    # Enable gradient checkpointing\n    if gradient_checkpointing:\n        unet.enable_gradient_checkpointing()\n\n    # Move models to GPU\n    vae.to(local_rank)\n    text_encoder.to(local_rank)\n\n    # Get the training dataset\n    train_dataset = WebVid10M(**train_data, is_image=image_finetune)\n    distributed_sampler = DistributedSampler(\n        train_dataset,\n        num_replicas=num_processes,\n        rank=global_rank,\n        shuffle=True,\n        seed=global_seed,\n    )\n\n    # DataLoaders creation:\n    train_dataloader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=train_batch_size,\n        shuffle=False,\n        sampler=distributed_sampler,\n        num_workers=num_workers,\n        pin_memory=True,\n        drop_last=True,\n    )\n\n    # Get the training iteration\n    if max_train_steps == -1:\n        assert max_train_epoch != -1\n        max_train_steps = max_train_epoch * len(train_dataloader)\n        \n    if checkpointing_steps == -1:\n        assert checkpointing_epochs != -1\n        checkpointing_steps = checkpointing_epochs * len(train_dataloader)\n\n    if scale_lr:\n        learning_rate = (learning_rate * gradient_accumulation_steps * train_batch_size * num_processes)\n\n    # Scheduler\n    lr_scheduler = get_scheduler(\n        lr_scheduler,\n        optimizer=optimizer,\n        num_warmup_steps=lr_warmup_steps * gradient_accumulation_steps,\n        num_training_steps=max_train_steps * gradient_accumulation_steps,\n    )\n\n    # Validation pipeline\n    if not image_finetune:\n        validation_pipeline = AnimationPipeline(\n            unet=unet, vae=vae, tokenizer=tokenizer, text_encoder=text_encoder, scheduler=noise_scheduler,\n        ).to(\"cuda\")\n    else:\n        validation_pipeline = StableDiffusionPipeline.from_pretrained(\n            pretrained_model_path,\n            unet=unet, vae=vae, tokenizer=tokenizer, text_encoder=text_encoder, scheduler=noise_scheduler, safety_checker=None,\n        )\n    validation_pipeline.enable_vae_slicing()\n\n    # DDP warpper\n    unet.to(local_rank)\n    unet = DDP(unet, device_ids=[local_rank], output_device=local_rank)\n\n    # We need to recalculate our total training steps as the size of the training dataloader may have changed.\n    num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n    # Afterwards we recalculate our number of training epochs\n    num_train_epochs = math.ceil(max_train_steps / num_update_steps_per_epoch)\n\n    # Train!\n    total_batch_size = train_batch_size * num_processes * gradient_accumulation_steps\n\n    if is_main_process:\n        logging.info(\"***** Running training *****\")\n        logging.info(f\"  Num examples = {len(train_dataset)}\")\n        logging.info(f\"  Num Epochs = {num_train_epochs}\")\n        logging.info(f\"  Instantaneous batch size per device = {train_batch_size}\")\n        logging.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n        logging.info(f\"  Gradient Accumulation steps = {gradient_accumulation_steps}\")\n        logging.info(f\"  Total optimization steps = {max_train_steps}\")\n    global_step = 0\n    first_epoch = 0\n\n    # Only show the progress bar once on each machine.\n    progress_bar = tqdm(range(global_step, max_train_steps), disable=not is_main_process)\n    progress_bar.set_description(\"Steps\")\n\n    # Support mixed-precision training\n    scaler = torch.cuda.amp.GradScaler() if mixed_precision_training else None\n\n    for epoch in range(first_epoch, num_train_epochs):\n        train_dataloader.sampler.set_epoch(epoch)\n        unet.train()\n        \n        for step, batch in enumerate(train_dataloader):\n            if cfg_random_null_text:\n                batch['text'] = [name if random.random() > cfg_random_null_text_ratio else \"\" for name in batch['text']]\n                \n            # Data batch sanity check\n            if epoch == first_epoch and step == 0:\n                pixel_values, texts = batch['pixel_values'].cpu(), batch['text']\n                if not image_finetune:\n                    pixel_values = rearrange(pixel_values, \"b f c h w -> b c f h w\")\n                    for idx, (pixel_value, text) in enumerate(zip(pixel_values, texts)):\n                        pixel_value = pixel_value[None, ...]\n                        save_videos_grid(pixel_value, f\"{output_dir}/sanity_check/{'-'.join(text.replace('/', '').split()[:10]) if not text == '' else f'{global_rank}-{idx}'}.gif\", rescale=True)\n                else:\n                    for idx, (pixel_value, text) in enumerate(zip(pixel_values, texts)):\n                        pixel_value = pixel_value / 2. + 0.5\n                        torchvision.utils.save_image(pixel_value, f\"{output_dir}/sanity_check/{'-'.join(text.replace('/', '').split()[:10]) if not text == '' else f'{global_rank}-{idx}'}.png\")\n                    \n            ### >>>> Training >>>> ###\n            \n            # Convert videos to latent space            \n            pixel_values = batch[\"pixel_values\"].to(local_rank)\n            video_length = pixel_values.shape[1]\n            with torch.no_grad():\n                if not image_finetune:\n                    pixel_values = rearrange(pixel_values, \"b f c h w -> (b f) c h w\")\n                    latents = vae.encode(pixel_values).latent_dist\n                    latents = latents.sample()\n                    latents = rearrange(latents, \"(b f) c h w -> b c f h w\", f=video_length)\n                else:\n                    latents = vae.encode(pixel_values).latent_dist\n                    latents = latents.sample()\n\n                latents = latents * 0.18215\n\n            # Sample noise that we'll add to the latents\n            noise = torch.randn_like(latents)\n            bsz = latents.shape[0]\n            \n            # Sample a random timestep for each video\n            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n            timesteps = timesteps.long()\n            \n            # Add noise to the latents according to the noise magnitude at each timestep\n            # (this is the forward diffusion process)\n            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n            \n            # Get the text embedding for conditioning\n            with torch.no_grad():\n                prompt_ids = tokenizer(\n                    batch['text'], max_length=tokenizer.model_max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n                ).input_ids.to(latents.device)\n                encoder_hidden_states = text_encoder(prompt_ids)[0]\n                \n            # Get the target for loss depending on the prediction type\n            if noise_scheduler.config.prediction_type == \"epsilon\":\n                target = noise\n            elif noise_scheduler.config.prediction_type == \"v_prediction\":\n                raise NotImplementedError\n            else:\n                raise ValueError(f\"Unknown prediction type {noise_scheduler.config.prediction_type}\")\n\n            # Predict the noise residual and compute loss\n            # Mixed-precision training\n            with torch.cuda.amp.autocast(enabled=mixed_precision_training):\n                model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n                loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n\n            optimizer.zero_grad()\n\n            # Backpropagate\n            if mixed_precision_training:\n                scaler.scale(loss).backward()\n                \"\"\" >>> gradient clipping >>> \"\"\"\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(unet.parameters(), max_grad_norm)\n                \"\"\" <<< gradient clipping <<< \"\"\"\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                loss.backward()\n                \"\"\" >>> gradient clipping >>> \"\"\"\n                torch.nn.utils.clip_grad_norm_(unet.parameters(), max_grad_norm)\n                \"\"\" <<< gradient clipping <<< \"\"\"\n                optimizer.step()\n\n            lr_scheduler.step()\n            progress_bar.update(1)\n            global_step += 1\n            \n            ### <<<< Training <<<< ###\n            \n            # Wandb logging\n            if is_main_process and (not is_debug) and use_wandb:\n                wandb.log({\"train_loss\": loss.item()}, step=global_step)\n                \n            # Save checkpoint\n            if is_main_process and (global_step % checkpointing_steps == 0 or step == len(train_dataloader) - 1):\n                save_path = os.path.join(output_dir, f\"checkpoints\")\n                state_dict = {\n                    \"epoch\": epoch,\n                    \"global_step\": global_step,\n                    \"state_dict\": unet.state_dict(),\n                }\n                if step == len(train_dataloader) - 1:\n                    torch.save(state_dict, os.path.join(save_path, f\"checkpoint-epoch-{epoch+1}.ckpt\"))\n                else:\n                    torch.save(state_dict, os.path.join(save_path, f\"checkpoint.ckpt\"))\n                logging.info(f\"Saved state to {save_path} (global_step: {global_step})\")\n                \n            # Periodically validation\n            if is_main_process and (global_step % validation_steps == 0 or global_step in validation_steps_tuple):\n                samples = []\n                \n                generator = torch.Generator(device=latents.device)\n                generator.manual_seed(global_seed)\n                \n                height = train_data.sample_size[0] if not isinstance(train_data.sample_size, int) else train_data.sample_size\n                width  = train_data.sample_size[1] if not isinstance(train_data.sample_size, int) else train_data.sample_size\n\n                prompts = validation_data.prompts[:2] if global_step < 1000 and (not image_finetune) else validation_data.prompts\n\n                for idx, prompt in enumerate(prompts):\n                    if not image_finetune:\n                        sample = validation_pipeline(\n                            prompt,\n                            generator    = generator,\n                            video_length = train_data.sample_n_frames,\n                            height       = height,\n                            width        = width,\n                            **validation_data,\n                        ).videos\n                        save_videos_grid(sample, f\"{output_dir}/samples/sample-{global_step}/{idx}.gif\")\n                        samples.append(sample)\n                        \n                    else:\n                        sample = validation_pipeline(\n                            prompt,\n                            generator           = generator,\n                            height              = height,\n                            width               = width,\n                            num_inference_steps = validation_data.get(\"num_inference_steps\", 25),\n                            guidance_scale      = validation_data.get(\"guidance_scale\", 8.),\n                        ).images[0]\n                        sample = torchvision.transforms.functional.to_tensor(sample)\n                        samples.append(sample)\n                \n                if not image_finetune:\n                    samples = torch.concat(samples)\n                    save_path = f\"{output_dir}/samples/sample-{global_step}.gif\"\n                    save_videos_grid(samples, save_path)\n                    \n                else:\n                    samples = torch.stack(samples)\n                    save_path = f\"{output_dir}/samples/sample-{global_step}.png\"\n                    torchvision.utils.save_image(samples, save_path, nrow=4)\n\n                logging.info(f\"Saved samples to {save_path}\")\n                \n            logs = {\"step_loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0]}\n            progress_bar.set_postfix(**logs)\n            \n            if global_step >= max_train_steps:\n                break\n            \n    dist.destroy_process_group()\n\n\n\nif __name__ == \"__main__\":\n    config_path = \"configs/training/v1/training.yaml\"\n    launcher = \"pytorch\"\n    use_wandb = False\n\n    name = Path(config_path).stem\n    config = OmegaConf.load(config_path)\n\n    # Sadece belirli argümanlar geçiliyor, diğerleri varsayılan değerlerinde kalıyor\n    main(name=name, launcher=launcher, use_wandb=use_wandb, **config)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T13:53:23.461331Z","iopub.execute_input":"2024-08-16T13:53:23.461712Z","iopub.status.idle":"2024-08-16T13:53:23.889600Z","shell.execute_reply.started":"2024-08-16T13:53:23.461665Z","shell.execute_reply":"2024-08-16T13:53:23.888392Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 492\u001b[0m\n\u001b[1;32m    489\u001b[0m config \u001b[38;5;241m=\u001b[39m OmegaConf\u001b[38;5;241m.\u001b[39mload(config_path)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# Sadece belirli argümanlar geçiliyor, diğerleri varsayılan değerlerinde kalıyor\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_wandb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[24], line 129\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(image_finetune, name, use_wandb, launcher, output_dir, pretrained_model_path, train_data, validation_data, cfg_random_null_text, cfg_random_null_text_ratio, unet_checkpoint_path, unet_additional_kwargs, ema_decay, noise_scheduler_kwargs, max_train_epoch, max_train_steps, validation_steps, validation_steps_tuple, learning_rate, scale_lr, lr_warmup_steps, lr_scheduler, trainable_modules, num_workers, train_batch_size, adam_beta1, adam_beta2, adam_weight_decay, adam_epsilon, max_grad_norm, gradient_accumulation_steps, gradient_checkpointing, checkpointing_epochs, checkpointing_steps, mixed_precision_training, enable_xformers_memory_efficient_attention, global_seed, is_debug)\u001b[0m\n\u001b[1;32m    126\u001b[0m check_min_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.10.0.dev0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Initialize distributed training\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m local_rank      \u001b[38;5;241m=\u001b[39m \u001b[43minit_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m global_rank     \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mget_rank()\n\u001b[1;32m    131\u001b[0m num_processes   \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mget_world_size()\n","Cell \u001b[0;32mIn[24], line 47\u001b[0m, in \u001b[0;36minit_dist\u001b[0;34m(launcher, backend, port, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initializes distributed environment.\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m launcher \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRANK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     48\u001b[0m     num_gpus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m     49\u001b[0m     local_rank \u001b[38;5;241m=\u001b[39m rank \u001b[38;5;241m%\u001b[39m num_gpus\n","File \u001b[0;32m/opt/conda/lib/python3.10/os.py:680\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n","\u001b[0;31mKeyError\u001b[0m: 'RANK'"],"ename":"KeyError","evalue":"'RANK'","output_type":"error"}]}]}